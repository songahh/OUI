{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367a2f0e-af28-4655-ae0d-0e70986c30a1",
   "metadata": {},
   "source": [
    "# package load 및 device 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94566b67-71d7-40be-b347-69511d07dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ab04ef2-db19-43b7-816d-ac91764e1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9563b706-7ba9-40a2-adf1-43bc1525ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62d612d-ee7c-4fbf-855b-b874335d6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda:3\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf80b12-10cc-44bf-b23e-70ee954fa871",
   "metadata": {},
   "source": [
    "# 데이터세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f946a4-f839-47f4-8975-9abf6e6fdcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = []\n",
    "        self.labels = []\n",
    "        for i in dataset:\n",
    "            if len(i)!=2:\n",
    "                continue\n",
    "\n",
    "            self.sentences.append(transform([i[sent_idx]]))\n",
    "            self.labels.append(np.int32(i[label_idx]))\n",
    "        \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "937a4ba3-161d-40fb-96a3-64ea23dd8426",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuiDatasetLoader:\n",
    "    def __init__(self, train_path, train_name, test_path, test_name, batch_size, max_len):\n",
    "        train_dataset = nlp.data.TSVDataset(os.path.join(train_path, train_name), num_discard_samples=1)\n",
    "        test_dataset = nlp.data.TSVDataset(os.path.join(test_path, test_name), num_discard_samples=1)\n",
    "\n",
    "        self.bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")\n",
    "        tokenizer = get_tokenizer()\n",
    "        tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        data_train = BERTDataset(train_dataset, 0, 1, tok, max_len, True, False)\n",
    "        data_test = BERTDataset(test_dataset, 0, 1, tok, max_len, True, False)\n",
    "        \n",
    "        self.train_dataloader = DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "        self.test_dataloader = DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
    "\n",
    "    def get_pretrained_model(self):\n",
    "        return self.bertmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0595ffbe-d393-4278-83da-5e1f9cbba2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_v1.zip\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_v1.zip\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     dataloader\u001b[38;5;241m.\u001b[39mappend(\u001b[43mOuiDatasetLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m, in \u001b[0;36mOuiDatasetLoader.__init__\u001b[0;34m(self, train_path, train_name, test_path, test_name, batch_size, max_len)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len \u001b[38;5;241m=\u001b[39m max_len\n\u001b[0;32m---> 13\u001b[0m data_train \u001b[38;5;241m=\u001b[39m \u001b[43mBERTDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m data_test \u001b[38;5;241m=\u001b[39m BERTDataset(test_dataset, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, tok, max_len, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(data_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mBERTDataset.__init__\u001b[0;34m(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(i)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentences\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[43msent_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mint32(i[label_idx]))\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/gluonnlp/data/transforms.py:1013\u001b[0m, in \u001b[0;36mBERTSentenceTransform.__call__\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1011\u001b[0m     text_b \u001b[38;5;241m=\u001b[39m line[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1013\u001b[0m tokens_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m tokens_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pair:\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/gluonnlp/data/transforms.py:849\u001b[0m, in \u001b[0;36mBERTSPTokenizer.__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample):\n\u001b[1;32m    836\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03m        List of tokens\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/gluonnlp/data/transforms.py:853\u001b[0m, in \u001b[0;36mBERTSPTokenizer._tokenizer\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tokenizer\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    852\u001b[0m     split_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    854\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sub_token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenize_wordpiece(token):\n\u001b[1;32m    855\u001b[0m             split_tokens\u001b[38;5;241m.\u001b[39mappend(sub_token)\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/gluonnlp/data/transforms.py:649\u001b[0m, in \u001b[0;36mBERTBasicTokenizer.__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample):\n\u001b[1;32m    637\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m        List of tokens\u001b[39;00m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloader = []\n",
    "train_path = \"../dataset/train\"\n",
    "train_name = \"train.tsv\"\n",
    "test_path = \"../dataset/test\"\n",
    "test_name = \"valid.tsv\"\n",
    "batch_size = 128\n",
    "max_len = 100\n",
    "for i in range(0, 5):\n",
    "    dataloader.append(OuiDatasetLoader(os.path.join(train_path, \"split_{}\".format(i)), train_name, os.path.join(test_path, \"split_{}\".format(i)), test_name, batch_size, max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd63558-759b-434f-974e-f44dbaaeaf5b",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2fd913-1e2d-4457-b460-51e4a3c929ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=6,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c7cd3-5991-49cb-935c-7cf3311b836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oui:\n",
    "    def __init__(self, bertmodel, device, train_dataloader, test_dataloader, fixed, hp, log_interval, num_epochs):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.log_interval = log_interval\n",
    "    \n",
    "        # Hyper-parameter random sampling\n",
    "        params = dict()\n",
    "        if not fixed:\n",
    "            for name, value_info in hp.items():\n",
    "                #print(value_info, len(value_info))\n",
    "                if value_info[1] == 'max_grad_norm':\n",
    "                    params[name] = np.random.choice(value_info[0])\n",
    "                elif value_info[1] == 'int':\n",
    "                    params[name] = np.random.randint(min(value_info[0]), max(value_info[0])+1)\n",
    "                elif value_info[1] == 'float':\n",
    "                    params[name] = np.random.uniform(min(value_info[0]), max(value_info[0]))\n",
    "        else:\n",
    "            params['dr_rate']=0.2282168316541426 #0.3\n",
    "            params['learning_rate']=4.4397570365495904e-05 #5e-5\n",
    "            params['max_grad_norm']=3 #1\n",
    "            params['warmup_ratio']=0.2503085518907766 #0.1\n",
    "            params['weight_decay']=0.009198865305723895 #0.01\n",
    "        \n",
    "        self.params = params\n",
    "        print(self.params)\n",
    "\n",
    "        self.model=BERTClassifier(bertmodel,  dr_rate=params[\"dr_rate\"]).to(device)\n",
    "        ## weight decay \n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': params[\"weight_decay\"]},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        ## optimizer & loss\n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=params[\"learning_rate\"])\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        ## learning rate scheduler\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        t_total = len(self.train_dataloader) * num_epochs\n",
    "        warmup_step = int(t_total * params[\"warmup_ratio\"])\n",
    "        self.scheduler = get_cosine_schedule_with_warmup(self.optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "\n",
    "    def calc_accuracy(self, X,y):\n",
    "        max_vals, max_indices = torch.max(X, 1)\n",
    "        train_acc = (max_indices == y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "        return train_acc\n",
    "\n",
    "    def train(self, device):\n",
    "        self.train_verbose_dict = {}\n",
    "        self.train_score_dict = {}\n",
    "        self.test_score_dict = {}\n",
    "        self.params_list = []\n",
    "\n",
    "        max_acc = 0\n",
    "        self.be = 0\n",
    "        self.bestmodel = self.model\n",
    "        print(self.params)\n",
    "        for e in range(self.num_epochs):\n",
    "            train_acc = 0.0\n",
    "            test_acc = 0.0\n",
    "\n",
    "            train_loss = []\n",
    "            train_scores = []\n",
    "            self.model.train()\n",
    "            for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(self.train_dataloader), total=len(self.train_dataloader)):\n",
    "                self.optimizer.zero_grad()\n",
    "                token_ids = token_ids.long().to(device)\n",
    "                segment_ids = segment_ids.long().to(device)\n",
    "                valid_length= valid_length\n",
    "                label = label.long().to(device)\n",
    "                \n",
    "                out = self.model(token_ids, valid_length, segment_ids)\n",
    "                loss = self.loss_fn(out, label)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params[\"max_grad_norm\"])\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()  # Update learning rate schedule\n",
    "                train_acc += self.calc_accuracy(out, label)\n",
    "                \n",
    "                if batch_id % self.log_interval == 0:\n",
    "                    print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "                    train_loss.append(loss.data.cpu().numpy())\n",
    "                    train_scores.append(train_acc / (batch_id+1))\n",
    "            \n",
    "            print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "            self.train_score_dict[e] = train_acc / (batch_id+1)\n",
    "            self.train_verbose_dict[e] = (train_loss, train_scores) \n",
    "            \n",
    "            self.model.eval()\n",
    "            for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(self.test_dataloader), total=len(self.test_dataloader)):\n",
    "                token_ids = token_ids.long().to(device)\n",
    "                segment_ids = segment_ids.long().to(device)\n",
    "                valid_length= valid_length\n",
    "                label = label.long().to(device)\n",
    "                \n",
    "                out = self.model(token_ids, valid_length, segment_ids)\n",
    "                test_acc += self.calc_accuracy(out, label)\n",
    "            \n",
    "            print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "            self.test_score_dict[e] = test_acc / (batch_id+1)\n",
    "            if max_acc < self.test_score_dict[e]:\n",
    "                max_acc = self.test_score_dict[e]\n",
    "                self.bestmodel = self.model\n",
    "                self.be = e\n",
    "                \n",
    "        return self.bestmodel, self.train_score_dict[self.be], self.test_score_dict[self.be]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a05eaa-de64-4ef7-afc0-537c03df4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'hp': {\n",
    "        'dr_rate': ([1e-1, 5e-1], 'float'),\n",
    "        'learning_rate': ([1e-5, 1e-3], 'float'),\n",
    "        'max_grad_norm': ([1, 3, 5], 'max_grad_norm'),\n",
    "        'warmup_ratio': ([1e-2, 3e-1], 'float'),\n",
    "        'weight_decay': ([1e-4, 1e-2] , 'float'),\n",
    "    },\n",
    "    'log_interval': 200,\n",
    "    'num_epochs': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69200a1-6562-44ab-a185-b3dd6023c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dataloader[0].get_pretrained_model()\n",
    "oui = Oui(model, device, dataloader[0].train_dataloader,dataloader[0].test_dataloader, True, **config)\n",
    "_, train_score, test_score = oui.train(device)\n",
    "    \n",
    "print(\"train_score: {}, test_score: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90becbf4-1e7c-4d5e-89bb-302e9c4ed169",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 5):\n",
    "    model = dataloader[i].get_pretrained_model()\n",
    "    oui = Oui(model, device, dataloader[i].train_dataloader,dataloader[i].test_dataloader, False, **config)\n",
    "    _, train_score, test_score = oui.train(device)\n",
    "    \n",
    "    print(\"K {} / train_score: {}, test_score: {}\".format(i, train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd1caef-f02f-46e9-bd30-3c13b8abd4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ee507e2-b579-4cd9-aad0-de08ddcee74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr_rate': 0.2282168316541426, 'learning_rate': 4.4397570365495904e-05, 'max_grad_norm': 3, 'warmup_ratio': 0.2503085518907766, 'weight_decay': 0.009198865305723895}\n",
      "{'dr_rate': 0.2282168316541426, 'learning_rate': 4.4397570365495904e-05, 'max_grad_norm': 3, 'warmup_ratio': 0.2503085518907766, 'weight_decay': 0.009198865305723895}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e13b49abb63492398b97fb9f3373668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.8984081745147705 train acc 0.046875\n",
      "epoch 1 batch id 201 loss 1.6685549020767212 train acc 0.31082866915422885\n",
      "epoch 1 batch id 401 loss 1.3760613203048706 train acc 0.34435395885286785\n",
      "epoch 1 train acc 0.38195953169184077\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d99d00d05b4ba692ba17399e971cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.5363756613756614\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788d59f67c6c4d4696db9cfe270bdd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 1.4331247806549072 train acc 0.4609375\n",
      "epoch 2 batch id 201 loss 1.2579668760299683 train acc 0.5280628109452736\n",
      "epoch 2 batch id 401 loss 1.1521053314208984 train acc 0.5401340399002493\n",
      "epoch 2 train acc 0.5485604610662804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8e14f188444d248997dbb46c03bb27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.5829034391534392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025d4d48b0a84a808158c3240f5cc08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 1.2082579135894775 train acc 0.5234375\n",
      "epoch 3 batch id 201 loss 1.212241768836975 train acc 0.5775031094527363\n",
      "epoch 3 batch id 401 loss 1.0927236080169678 train acc 0.582333229426434\n",
      "epoch 3 train acc 0.5874990301055245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a899944edb4970986cb907b38a2d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.5885168650793651\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7583a1c5b6f0464f80cfd7da7954bd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 1.0979316234588623 train acc 0.5859375\n",
      "epoch 4 batch id 201 loss 1.1112815141677856 train acc 0.6110851990049752\n",
      "epoch 4 batch id 401 loss 0.9950424432754517 train acc 0.6185512780548629\n",
      "epoch 4 train acc 0.6245495378991655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d9cb402a954b318f22285f333e2cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.5858878968253968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e744e16d8241f881c1e422c9380795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 1.1435667276382446 train acc 0.5859375\n",
      "epoch 5 batch id 201 loss 1.0327448844909668 train acc 0.6517412935323383\n",
      "epoch 5 batch id 401 loss 0.8891943097114563 train acc 0.6623675187032418\n",
      "epoch 5 train acc 0.6699368275398304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bee1f2f57dc48b88182594a4ceeba88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.5676421957671958\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75895e8c27394fc18ae487a1e467aae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.9127681851387024 train acc 0.6875\n",
      "epoch 6 batch id 201 loss 0.8819690942764282 train acc 0.7002487562189055\n",
      "epoch 6 batch id 401 loss 0.7399062514305115 train acc 0.7127688591022444\n",
      "epoch 6 train acc 0.7227545865232086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52638cf4148740059400ee0470725e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 test acc 0.5739252645502645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4306e99c5d38492980e374535a1dd322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.8440873026847839 train acc 0.7109375\n",
      "epoch 7 batch id 201 loss 0.7750044465065002 train acc 0.7526819029850746\n",
      "epoch 7 batch id 401 loss 0.6879240870475769 train acc 0.7609491895261845\n",
      "epoch 7 train acc 0.767971066970136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e46c09b69d4e29be4a4c4cc48e5149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 test acc 0.5681712962962963\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5fc31345044a7c892c5a258fb8c7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.8340594172477722 train acc 0.703125\n",
      "epoch 8 batch id 201 loss 0.6033045053482056 train acc 0.7923662935323383\n",
      "epoch 8 batch id 401 loss 0.5552154183387756 train acc 0.8002454800498753\n",
      "epoch 8 train acc 0.8046875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb0291c843e430b8bbebb41f491f882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 test acc 0.5893931878306878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df960b4e717541ac9c51acfb3027ec77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.7865308523178101 train acc 0.703125\n",
      "epoch 9 batch id 201 loss 0.6974712014198303 train acc 0.822255907960199\n",
      "epoch 9 batch id 401 loss 0.4908873736858368 train acc 0.8280665523690773\n",
      "epoch 9 train acc 0.8318057495344506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d2a6240e444c4db46408c16a496418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 test acc 0.580406746031746\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21f5535002c42a7a33adf9e05898653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/537 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.7151694893836975 train acc 0.7578125\n",
      "epoch 10 batch id 201 loss 0.6126967072486877 train acc 0.841728855721393\n",
      "epoch 10 batch id 401 loss 0.47557756304740906 train acc 0.8441591334164589\n",
      "epoch 10 train acc 0.8469361033519553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1a6c2e3eb248e7891d4bf2b9099e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 test acc 0.5832423941798941\n",
      "train_score: 0.8046875, test_score: 0.5893931878306878\n"
     ]
    }
   ],
   "source": [
    "model = dataloader[0].get_pretrained_model()\n",
    "oui = Oui(model, device, dataloader[0].train_dataloader,dataloader[0].test_dataloader, True, **config)\n",
    "_, train_score, test_score = oui.train(device)\n",
    "    \n",
    "print(\"train_score: {}, test_score: {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1308c-a8b4-4c4a-8141-3c29832c3daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oui3.8",
   "language": "python",
   "name": "oui3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
