{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397d8fd7-02c5-4d51-a2f3-9ecd4852a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc54d7a0-7f0b-49fd-b521-36c134bc29f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = torch.device(\"cuda:3\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf83565f-ecc6-4840-923e-ed4d48528106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import gluon\n",
    "import mxnet as mx\n",
    "import gluonnlp as nlp\n",
    "\n",
    "from kobert import get_mxnet_kobert_model\n",
    "from kobert import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119bc6e3-8f80-44dc-8827-3724b88cbd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ctx = mx.cpu()\n",
    "ctx = mx.gpu(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02e8ecf-3a28-4efd-98d9-0f3d9d3bd304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/mxnet_kobert_45b6957552.params\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/ndarray/ndarray.cc\", line 1297\nMXNetError: GPU is not enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bert_base, vocab \u001b[38;5;241m=\u001b[39m \u001b[43mget_mxnet_kobert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_classifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcachedir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.cache\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oui/KoBERT/kobert/mxnet_kobert.py:97\u001b[0m, in \u001b[0;36mget_mxnet_kobert_model\u001b[0;34m(use_pooler, use_decoder, use_classifier, ctx, cachedir)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# download vocab\u001b[39;00m\n\u001b[1;32m     96\u001b[0m vocab_path \u001b[38;5;241m=\u001b[39m get_tokenizer()\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_kobert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pooler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/oui/KoBERT/kobert/mxnet_kobert.py:81\u001b[0m, in \u001b[0;36mget_mxnet_kobert_model.<locals>.get_kobert_model\u001b[0;34m(model_file, vocab_file, use_pooler, use_decoder, use_classifier, ctx)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# BERT\u001b[39;00m\n\u001b[1;32m     70\u001b[0m net \u001b[38;5;241m=\u001b[39m BERTModel(\n\u001b[1;32m     71\u001b[0m     encoder,\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mlen\u001b[39m(vocab_b_obj\u001b[38;5;241m.\u001b[39midx_to_token),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     use_classifier\u001b[38;5;241m=\u001b[39muse_classifier,\n\u001b[1;32m     80\u001b[0m )\n\u001b[0;32m---> 81\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m net\u001b[38;5;241m.\u001b[39mload_parameters(model_file, ctx, ignore_extra\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (net, vocab_b_obj)\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/gluon/block.py:657\u001b[0m, in \u001b[0;36mBlock.initialize\u001b[0;34m(self, init, ctx, verbose, force_reinit)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, init\u001b[38;5;241m=\u001b[39minitializer\u001b[38;5;241m.\u001b[39mUniform(), ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    641\u001b[0m                force_reinit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    642\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;124;03m    Equivalent to ``block.collect_params().initialize(...)``\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124;03m        Whether to force re-initialization if parameter is already initialized.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reinit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/gluon/parameter.py:896\u001b[0m, in \u001b[0;36mParameterDict.initialize\u001b[0;34m(self, init, ctx, verbose, force_reinit)\u001b[0m\n\u001b[1;32m    894\u001b[0m     init\u001b[38;5;241m.\u001b[39mset_verbosity(verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 896\u001b[0m     \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reinit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_reinit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/gluon/parameter.py:472\u001b[0m, in \u001b[0;36mParameter.initialize\u001b[0;34m(self, init, ctx, default_init, force_reinit)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot initialize Parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m because it has \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    469\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid shape: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)))\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred_init \u001b[38;5;241m=\u001b[39m (init, ctx, default_init, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finish_deferred_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/gluon/parameter.py:353\u001b[0m, in \u001b[0;36mParameter._finish_deferred_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m     data \u001b[38;5;241m=\u001b[39m zeros_fn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    350\u001b[0m     initializer\u001b[38;5;241m.\u001b[39mcreate(default_init)(\n\u001b[1;32m    351\u001b[0m         initializer\u001b[38;5;241m.\u001b[39mInitDesc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__init__\u001b[39m\u001b[38;5;124m'\u001b[39m: init}), data)\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/gluon/parameter.py:365\u001b[0m, in \u001b[0;36mParameter._init_impl\u001b[0;34m(self, data, ctx_list)\u001b[0m\n\u001b[1;32m    362\u001b[0m         dev_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    363\u001b[0m     dev_list[ctx\u001b[38;5;241m.\u001b[39mdevice_id] \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mcopyto(ctx) \u001b[38;5;28;01mfor\u001b[39;00m ctx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx_list]\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_grad()\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/gluon/parameter.py:365\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m         dev_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    363\u001b[0m     dev_list[ctx\u001b[38;5;241m.\u001b[39mdevice_id] \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ctx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ctx_list]\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_grad()\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/ndarray/ndarray.py:2671\u001b[0m, in \u001b[0;36mNDArray.copyto\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Context):\n\u001b[1;32m   2670\u001b[0m     hret \u001b[38;5;241m=\u001b[39m NDArray(_new_alloc_handle(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, other, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m-> 2671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copyto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2673\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopyto does not support type \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(other)))\n",
      "File \u001b[0;32m<string>:27\u001b[0m, in \u001b[0;36m_copyto\u001b[0;34m(data, out, name, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/_ctypes/ndarray.py:82\u001b[0m, in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out, is_np_op, output_is_list)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# return output stypes to avoid the c_api call for checking\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# a handle's stype in _ndarray_cls\u001b[39;00m\n\u001b[1;32m     80\u001b[0m out_stypes \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(ctypes\u001b[38;5;241m.\u001b[39mc_int)()\n\u001b[0;32m---> 82\u001b[0m \u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMXImperativeInvokeEx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_void_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mndargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_handle_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_str_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_str_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_stypes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m create_ndarray_fn \u001b[38;5;241m=\u001b[39m _global_var\u001b[38;5;241m.\u001b[39m_np_ndarray_cls \u001b[38;5;28;01mif\u001b[39;00m is_np_op \u001b[38;5;28;01melse\u001b[39;00m _global_var\u001b[38;5;241m.\u001b[39m_ndarray_cls\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m original_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/oui3.8/lib/python3.8/site-packages/mxnet/base.py:246\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mThis function will raise an exception when an error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m    return value from API calls.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_last_ffi_error()\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/ndarray/ndarray.cc\", line 1297\nMXNetError: GPU is not enabled"
     ]
    }
   ],
   "source": [
    "bert_base, vocab = get_mxnet_kobert_model(use_decoder=False, use_classifier=False, ctx=ctx, cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9825cff-a2d2-42c7-8338-3d012b2a6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2baafe9-ba1a-4fbf-b460-954986e48c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gluon.data.SimpleDataset([['나 보기가 역겨워', '김소월']])\n",
    "trans = nlp.data.BERTSentenceTransform(tok, max_seq_length=10)\n",
    "\n",
    "list(ds.transform(trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e231a-33b0-4d53-b49e-9992e7ed207f",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faf7b5c5-3dac-4d06-8cba-f873dd0d67a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-22 14:09:35--  http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
      "Resolving skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)... 52.219.58.130, 52.219.204.11, 52.219.146.79, ...\n",
      "Connecting to skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)|52.219.58.130|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [text/plain]\n",
      "Saving to: ‘.cache/ratings_train.txt’\n",
      "\n",
      ".cache/ratings_trai 100%[===================>]  13.95M  59.8MB/s    in 0.2s    \n",
      "\n",
      "2024-03-22 14:09:35 (59.8 MB/s) - ‘.cache/ratings_train.txt’ saved [14628807/14628807]\n",
      "\n",
      "--2024-03-22 14:09:36--  http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt\n",
      "Resolving skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)... 52.219.146.91, 52.219.204.11, 52.219.146.38, ...\n",
      "Connecting to skt-lsl-nlp-model.s3.amazonaws.com (skt-lsl-nlp-model.s3.amazonaws.com)|52.219.146.91|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [text/plain]\n",
      "Saving to: ‘.cache/ratings_test.txt’\n",
      "\n",
      ".cache/ratings_test 100%[===================>]   4.67M  19.5MB/s    in 0.2s    \n",
      "\n",
      "2024-03-22 14:09:36 (19.5 MB/s) - ‘.cache/ratings_test.txt’ saved [4893335/4893335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O .cache/ratings_train.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
    "!wget -O .cache/ratings_test.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0827bdd8-2263-495b-824a-948b0f9c7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\".cache/ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\".cache/ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba4a5653-2477-4683-9935-4da0ebe1ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(mx.gluon.data.Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        sent_dataset = gluon.data.SimpleDataset([[\n",
    "            i[sent_idx],\n",
    "        ] for i in dataset])\n",
    "        self.sentences = sent_dataset.transform(transform)\n",
    "        self.labels = gluon.data.SimpleDataset(\n",
    "            [np.array(np.int32(i[label_idx])) for i in dataset])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad132db3-90f8-49d6-991d-4ff919ef0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71040f80-6a41-4e32-9266-0cc80d30fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "415e56e7-1977-4943-bbb8-4b4eac59ef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Block):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 num_classes=2,\n",
    "                 dropout=None,\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(nn.Dense(units=num_classes))\n",
    "\n",
    "    def forward(self, inputs, token_types, valid_length=None):\n",
    "        _, pooler = self.bert(inputs, token_types, valid_length)\n",
    "        return self.classifier(pooler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf50fe08-2c01-46e3-8399-b19f1ef93b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "# 분류 레이어만 초기화 한다. \n",
    "model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "model.hybridize()\n",
    "\n",
    "# softmax cross entropy loss for classification\n",
    "loss_function = gluon.loss.SoftmaxCELoss()\n",
    "\n",
    "metric = mx.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcfeceaa-e64c-46ac-9ebe-a75edd40c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 5e-5\n",
    "\n",
    "train_dataloader = mx.gluon.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=int(batch_size/2), num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff4dcae5-ce8e-48e6-816d-02ab9f89e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(model.collect_params(), 'bertadam',\n",
    "                        {'learning_rate': lr, 'epsilon': 1e-9, 'wd':0.01})\n",
    "\n",
    "log_interval = 4\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95659063-77d5-4ca2-ba72-11128a9199dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayerNorm과 Bias에는 Weight Decay를 적용하지 않는다. \n",
    "for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n",
    "    v.wd_mult = 0.0\n",
    "params = [\n",
    "    p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8615572-618c-4379-977e-bb92cebd3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, data_iter, ctx=ctx):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    i = 0\n",
    "    for i, (t,v,s, label) in enumerate(data_iter):\n",
    "        token_ids = t.as_in_context(ctx)\n",
    "        valid_length = v.as_in_context(ctx)\n",
    "        segment_ids = s.as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "        acc.update(preds=output, labels=label)\n",
    "        if i > 1000:\n",
    "            break\n",
    "        i += 1\n",
    "    return(acc.get()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fdf4721-dc7e-43df-9cde-192450d615fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate warmup을 위한 준비 \n",
    "accumulate = 4\n",
    "step_size = batch_size * accumulate if accumulate else batch_size\n",
    "num_train_examples = len(data_train)\n",
    "num_train_steps = int(num_train_examples / step_size * num_epochs)\n",
    "warmup_ratio = 0.1\n",
    "num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
    "step_num = 0\n",
    "all_model_params = model.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d18c8767-d8c0-4a98-b95f-6609de3f64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set grad_req if gradient accumulation is required\n",
    "if accumulate and accumulate > 1:\n",
    "    for p in params:\n",
    "        p.grad_req = 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "925cc7d3-21e9-4eb0-93e6-ab065fb14f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3cc827a865437da1205ceff0a7aea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 50/4688] loss=8.7154, lr=0.0000051282, acc=0.512\n",
      "[Epoch 1 Batch 100/4688] loss=7.9294, lr=0.0000102564, acc=0.575\n",
      "[Epoch 1 Batch 150/4688] loss=6.2848, lr=0.0000158120, acc=0.639\n",
      "[Epoch 1 Batch 200/4688] loss=5.8165, lr=0.0000209402, acc=0.678\n",
      "[Epoch 1 Batch 250/4688] loss=6.0810, lr=0.0000264957, acc=0.697\n",
      "[Epoch 1 Batch 300/4688] loss=5.7712, lr=0.0000316239, acc=0.713\n",
      "[Epoch 1 Batch 350/4688] loss=5.0181, lr=0.0000371795, acc=0.729\n",
      "[Epoch 1 Batch 400/4688] loss=5.0419, lr=0.0000423077, acc=0.741\n",
      "[Epoch 1 Batch 450/4688] loss=5.3596, lr=0.0000478632, acc=0.750\n",
      "[Epoch 1 Batch 500/4688] loss=5.3382, lr=0.0000496679, acc=0.756\n",
      "[Epoch 1 Batch 550/4688] loss=4.7881, lr=0.0000490512, acc=0.763\n",
      "[Epoch 1 Batch 600/4688] loss=4.4414, lr=0.0000484820, acc=0.770\n",
      "[Epoch 1 Batch 650/4688] loss=4.5175, lr=0.0000478653, acc=0.776\n",
      "[Epoch 1 Batch 700/4688] loss=4.4887, lr=0.0000472960, acc=0.781\n",
      "[Epoch 1 Batch 750/4688] loss=4.6268, lr=0.0000466793, acc=0.785\n",
      "[Epoch 1 Batch 800/4688] loss=4.4855, lr=0.0000461101, acc=0.789\n",
      "[Epoch 1 Batch 850/4688] loss=3.9330, lr=0.0000454934, acc=0.794\n",
      "[Epoch 1 Batch 900/4688] loss=4.4155, lr=0.0000449241, acc=0.796\n",
      "[Epoch 1 Batch 950/4688] loss=4.1133, lr=0.0000443074, acc=0.800\n",
      "[Epoch 1 Batch 1000/4688] loss=4.4571, lr=0.0000437381, acc=0.803\n",
      "[Epoch 1 Batch 1050/4688] loss=3.7774, lr=0.0000431214, acc=0.806\n",
      "[Epoch 1 Batch 1100/4688] loss=4.1978, lr=0.0000425522, acc=0.809\n",
      "[Epoch 1 Batch 1150/4688] loss=3.6270, lr=0.0000419355, acc=0.812\n",
      "[Epoch 1 Batch 1200/4688] loss=4.0071, lr=0.0000413662, acc=0.814\n",
      "[Epoch 1 Batch 1250/4688] loss=4.2440, lr=0.0000407495, acc=0.816\n",
      "[Epoch 1 Batch 1300/4688] loss=3.7599, lr=0.0000401803, acc=0.818\n",
      "[Epoch 1 Batch 1350/4688] loss=3.8028, lr=0.0000395636, acc=0.820\n",
      "[Epoch 1 Batch 1400/4688] loss=3.9161, lr=0.0000389943, acc=0.822\n",
      "[Epoch 1 Batch 1450/4688] loss=3.8761, lr=0.0000383776, acc=0.823\n",
      "[Epoch 1 Batch 1500/4688] loss=4.0553, lr=0.0000378083, acc=0.825\n",
      "[Epoch 1 Batch 1550/4688] loss=3.9795, lr=0.0000371917, acc=0.826\n",
      "[Epoch 1 Batch 1600/4688] loss=3.9854, lr=0.0000366224, acc=0.827\n",
      "[Epoch 1 Batch 1650/4688] loss=3.7908, lr=0.0000360057, acc=0.828\n",
      "[Epoch 1 Batch 1700/4688] loss=4.1153, lr=0.0000354364, acc=0.829\n",
      "[Epoch 1 Batch 1750/4688] loss=3.7927, lr=0.0000348197, acc=0.830\n",
      "[Epoch 1 Batch 1800/4688] loss=3.6818, lr=0.0000342505, acc=0.831\n",
      "[Epoch 1 Batch 1850/4688] loss=3.5179, lr=0.0000336338, acc=0.833\n",
      "[Epoch 1 Batch 1900/4688] loss=4.0006, lr=0.0000330645, acc=0.833\n",
      "[Epoch 1 Batch 1950/4688] loss=3.9243, lr=0.0000324478, acc=0.834\n",
      "[Epoch 1 Batch 2000/4688] loss=3.6319, lr=0.0000318786, acc=0.835\n",
      "[Epoch 1 Batch 2050/4688] loss=3.7794, lr=0.0000312619, acc=0.836\n",
      "[Epoch 1 Batch 2100/4688] loss=3.2534, lr=0.0000306926, acc=0.837\n",
      "[Epoch 1 Batch 2150/4688] loss=3.9004, lr=0.0000300759, acc=0.838\n",
      "[Epoch 1 Batch 2200/4688] loss=3.7693, lr=0.0000295066, acc=0.839\n",
      "[Epoch 1 Batch 2250/4688] loss=3.6862, lr=0.0000288899, acc=0.839\n",
      "[Epoch 1 Batch 2300/4688] loss=3.4200, lr=0.0000283207, acc=0.840\n",
      "[Epoch 1 Batch 2350/4688] loss=3.6804, lr=0.0000277040, acc=0.841\n",
      "[Epoch 1 Batch 2400/4688] loss=3.8445, lr=0.0000271347, acc=0.842\n",
      "[Epoch 1 Batch 2450/4688] loss=3.6469, lr=0.0000265180, acc=0.842\n",
      "[Epoch 1 Batch 2500/4688] loss=3.5765, lr=0.0000259488, acc=0.843\n",
      "[Epoch 1 Batch 2550/4688] loss=3.8206, lr=0.0000253321, acc=0.844\n",
      "[Epoch 1 Batch 2600/4688] loss=3.3778, lr=0.0000247628, acc=0.844\n",
      "[Epoch 1 Batch 2650/4688] loss=3.6055, lr=0.0000241461, acc=0.845\n",
      "[Epoch 1 Batch 2700/4688] loss=3.9729, lr=0.0000235769, acc=0.846\n",
      "[Epoch 1 Batch 2750/4688] loss=3.3365, lr=0.0000229602, acc=0.846\n",
      "[Epoch 1 Batch 2850/4688] loss=3.4389, lr=0.0000217742, acc=0.848\n",
      "[Epoch 1 Batch 2900/4688] loss=3.6347, lr=0.0000212049, acc=0.848\n",
      "[Epoch 1 Batch 2950/4688] loss=3.5302, lr=0.0000205882, acc=0.849\n",
      "[Epoch 1 Batch 3000/4688] loss=3.8385, lr=0.0000200190, acc=0.849\n",
      "[Epoch 1 Batch 3050/4688] loss=3.3144, lr=0.0000194023, acc=0.850\n",
      "[Epoch 1 Batch 3100/4688] loss=3.6147, lr=0.0000188330, acc=0.851\n",
      "[Epoch 1 Batch 3150/4688] loss=3.4553, lr=0.0000182163, acc=0.851\n",
      "[Epoch 1 Batch 3200/4688] loss=3.5176, lr=0.0000176471, acc=0.851\n",
      "[Epoch 1 Batch 3250/4688] loss=3.4016, lr=0.0000170304, acc=0.852\n",
      "[Epoch 1 Batch 3300/4688] loss=3.2567, lr=0.0000164611, acc=0.852\n",
      "[Epoch 1 Batch 3350/4688] loss=3.4222, lr=0.0000158444, acc=0.853\n",
      "[Epoch 1 Batch 3400/4688] loss=3.4586, lr=0.0000152751, acc=0.853\n",
      "[Epoch 1 Batch 3450/4688] loss=3.5285, lr=0.0000146584, acc=0.854\n",
      "[Epoch 1 Batch 3500/4688] loss=3.4269, lr=0.0000140892, acc=0.854\n",
      "[Epoch 1 Batch 3550/4688] loss=3.3493, lr=0.0000134725, acc=0.854\n",
      "[Epoch 1 Batch 3600/4688] loss=3.4291, lr=0.0000129032, acc=0.855\n",
      "[Epoch 1 Batch 3650/4688] loss=3.0897, lr=0.0000122865, acc=0.855\n",
      "[Epoch 1 Batch 3700/4688] loss=3.5452, lr=0.0000117173, acc=0.856\n",
      "[Epoch 1 Batch 3750/4688] loss=3.4393, lr=0.0000111006, acc=0.856\n",
      "[Epoch 1 Batch 3800/4688] loss=3.2565, lr=0.0000105313, acc=0.857\n",
      "[Epoch 1 Batch 3850/4688] loss=3.4109, lr=0.0000099146, acc=0.857\n",
      "[Epoch 1 Batch 3900/4688] loss=3.5917, lr=0.0000093454, acc=0.857\n",
      "[Epoch 1 Batch 3950/4688] loss=3.0639, lr=0.0000087287, acc=0.858\n",
      "[Epoch 1 Batch 4000/4688] loss=3.0339, lr=0.0000081594, acc=0.858\n",
      "[Epoch 1 Batch 4050/4688] loss=3.1458, lr=0.0000075427, acc=0.859\n",
      "[Epoch 1 Batch 4100/4688] loss=3.6159, lr=0.0000069734, acc=0.859\n",
      "[Epoch 1 Batch 4150/4688] loss=3.0681, lr=0.0000063567, acc=0.860\n",
      "[Epoch 1 Batch 4200/4688] loss=3.5052, lr=0.0000057875, acc=0.860\n",
      "[Epoch 1 Batch 4250/4688] loss=3.5805, lr=0.0000051708, acc=0.860\n",
      "[Epoch 1 Batch 4300/4688] loss=3.2045, lr=0.0000046015, acc=0.861\n",
      "[Epoch 1 Batch 4350/4688] loss=3.3418, lr=0.0000039848, acc=0.861\n",
      "[Epoch 1 Batch 4400/4688] loss=3.0706, lr=0.0000034156, acc=0.861\n",
      "[Epoch 1 Batch 4450/4688] loss=3.3541, lr=0.0000027989, acc=0.862\n",
      "[Epoch 1 Batch 4500/4688] loss=3.3240, lr=0.0000022296, acc=0.862\n",
      "[Epoch 1 Batch 4550/4688] loss=2.8144, lr=0.0000016129, acc=0.863\n",
      "[Epoch 1 Batch 4600/4688] loss=3.1583, lr=0.0000010436, acc=0.863\n",
      "[Epoch 1 Batch 4650/4688] loss=2.9154, lr=0.0000004269, acc=0.863\n",
      "Test Acc : 0.8931511976047904\n"
     ]
    }
   ],
   "source": [
    "for epoch_id in range(num_epochs):\n",
    "    metric.reset()\n",
    "    step_loss = 0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        if step_num < num_warmup_steps:\n",
    "            new_lr = lr * step_num / num_warmup_steps\n",
    "        else:\n",
    "            non_warmup_steps = step_num - num_warmup_steps\n",
    "            offset = non_warmup_steps / (num_train_steps - num_warmup_steps)\n",
    "            new_lr = lr - offset * lr\n",
    "        trainer.set_learning_rate(new_lr)\n",
    "        with mx.autograd.record():\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "        # backward computation\n",
    "        ls.backward()\n",
    "        if not accumulate or (batch_id + 1) % accumulate == 0:\n",
    "          trainer.allreduce_grads()\n",
    "          nlp.utils.clip_grad_global_norm(params, 1)\n",
    "          trainer.update(accumulate if accumulate else 1)\n",
    "          step_num += 1\n",
    "          if accumulate and accumulate > 1:\n",
    "              # set grad to zero for gradient accumulation\n",
    "              all_model_params.zero_grad()\n",
    "\n",
    "        step_loss += ls.asscalar()\n",
    "        metric.update([label], [out])\n",
    "        if (batch_id + 1) % (50) == 0:\n",
    "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.10f}, acc={:.3f}'\n",
    "                         .format(epoch_id + 1, batch_id + 1, len(train_dataloader),\n",
    "                                 step_loss / log_interval,\n",
    "                                 trainer.learning_rate, metric.get()[1]))\n",
    "            step_loss = 0\n",
    "    test_acc = evaluate_accuracy(model, test_dataloader, ctx)\n",
    "    print('Test Acc : {}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oui3.8",
   "language": "python",
   "name": "oui3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
