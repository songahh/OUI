{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab0fa98-a2be-40f8-8163-0a67346a66f4",
   "metadata": {},
   "source": [
    "# OUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e0d87-5897-4adc-9873-fd94ace9576b",
   "metadata": {},
   "source": [
    "### package load 및 device 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51da7edb-72f9-4bcc-a370-a136d8d28884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a33eca-3547-4a04-8846-f1e920d6c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d53e82-ada4-4c6d-bc15-ef7da3927778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8d9bff-8978-4c1b-a257-d56653465083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "#os.environ[\"TORCH_USE_CUDA_DSA\"] = '1'\n",
    "#device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.cuda.device_count()\n",
    "device = torch.device(\"cuda:3\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72321491-de20-412f-8ef0-4980c75b404b",
   "metadata": {},
   "source": [
    "### 데이터세트 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ca0dbd7c-2c6a-4822-a8a1-3be5fbfb822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = nlp.data.TSVDataset(os.path.join(\"../dataset/train\", \"train.tsv\"), num_discard_samples=1)\n",
    "test_dataset = nlp.data.TSVDataset(os.path.join(\"../dataset/test\", \"valid.tsv\"), num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "84543657-a646-4d6b-9e6f-6bd33cd621c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_v1.zip\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "447fc987-6a51-4419-9bd6-2cc50f440ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "462e4221-0d71-4eab-b18f-817b942c0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = []\n",
    "        self.labels = []\n",
    "        for i in dataset:\n",
    "            if len(i)!=2:\n",
    "                continue\n",
    "\n",
    "            self.sentences.append(transform([i[sent_idx]]))\n",
    "            self.labels.append(np.int32(i[label_idx]))\n",
    "        \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d33d8de-1932-438b-a777-2f9ee6627a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(train_dataset, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(test_dataset, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31c5960b-e6db-4c22-946a-bc39d46c864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e104ed-1275-41e0-8896-68993800a563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c843ccc-488f-408c-a0ca-a89aa8e173fa",
   "metadata": {},
   "source": [
    "### kobert load\n",
    "* 하이퍼파라미터 조정\n",
    "  * dropout 비율\n",
    "  * learning rate\n",
    "  * warmup_ratio\n",
    "  * learning_rate\n",
    "  * max_grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "24c48518-e358-4082-8ea0-35e0f31bb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=6,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49db92d8-6561-4435-b52f-1ccd3d047758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2282168316541426\n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1d7f8-4380-4ed0-bf3d-3e6f32cc3d9f",
   "metadata": {},
   "source": [
    "### 학습\n",
    "* best 모델 저장\n",
    "* epoch 수: 최대 20회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8373d3ee-a1eb-4e24-92dd-921b3c1c53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "warmup_ratio = 0.1 # 0.2503085518907766 # 학습률 warm up 비율로 학습률을 초기에 점진적으로 높이는데 사용\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1 # Gradient clipping에 사용됨 \n",
    "log_interval = 200\n",
    "learning_rate = 5e-5 #4.4397570365495904e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "430e97a1-4395-4a40-977c-ccb6d9fac93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.009198865305723895},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f14711b8-1dce-406f-b22e-7c4b81258a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5905dd1-41f8-4f79-a48a-e4eb6d4cf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48db2088-5dd7-41cd-8473-13b73c6851d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fc3d482a-d279-4006-9a75-ac535384deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24161bdd-2b89-453b-ace0-df8a1f8e27bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a47119f489c469db3dd2d4e37ec46a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 1.814565658569336 train acc 0.1640625\n",
      "epoch 1 batch id 201 loss 1.4248244762420654 train acc 0.3113339552238806\n",
      "epoch 1 batch id 401 loss 1.2490034103393555 train acc 0.3847023067331671\n",
      "epoch 1 batch id 601 loss 1.0381593704223633 train acc 0.43924188851913476\n",
      "epoch 1 train acc 0.4525079172876304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c89574f79d4eaf84e5b083d5f09c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.5688887444960861\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82730ca70b654cc29195af580ab68ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 1.1160815954208374 train acc 0.6015625\n",
      "epoch 2 batch id 201 loss 1.0192915201187134 train acc 0.562383395522388\n",
      "epoch 2 batch id 401 loss 1.1564719676971436 train acc 0.566104270573566\n",
      "epoch 2 batch id 601 loss 0.9732457995414734 train acc 0.5743682404326124\n",
      "epoch 2 train acc 0.5777352995967389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1f3fd9ef204904ae1357249ea4943e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 test acc 0.587013438723092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fa41aa86c44bbc89a8ad72902ac359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 1.0886294841766357 train acc 0.5625\n",
      "epoch 3 batch id 201 loss 0.9133548140525818 train acc 0.6084810323383084\n",
      "epoch 3 batch id 401 loss 1.0644561052322388 train acc 0.611284289276808\n",
      "epoch 3 batch id 601 loss 0.8846819996833801 train acc 0.6203852953410982\n",
      "epoch 3 train acc 0.6230453340054353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd4edc37963494e828b9a4193f19194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 test acc 0.5813865786040443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9b10b46d664eef8052bb2e12d00379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 0.9813555479049683 train acc 0.59375\n",
      "epoch 4 batch id 201 loss 0.7628929615020752 train acc 0.6520133706467661\n",
      "epoch 4 batch id 401 loss 0.9633272886276245 train acc 0.6560162094763092\n",
      "epoch 4 batch id 601 loss 0.7674992084503174 train acc 0.6667273294509152\n",
      "epoch 4 train acc 0.6701511407469097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a907eb8dbe7d462fa9b96e0c61c80617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 test acc 0.5883269885437051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b467fe688370438a9ccb44eaadf4f840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 0.8384386897087097 train acc 0.6640625\n",
      "epoch 5 batch id 201 loss 0.655267596244812 train acc 0.7009483830845771\n",
      "epoch 5 batch id 401 loss 0.9494495391845703 train acc 0.7059304862842892\n",
      "epoch 5 batch id 601 loss 0.6989797353744507 train acc 0.7178010607321131\n",
      "epoch 5 train acc 0.7211683341369335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d5dba1f20e40aead285f2160fcdc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 test acc 0.5772363472358121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936c493156f44f5f8c67bb835c6e6f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 0.6963568925857544 train acc 0.765625\n",
      "epoch 6 batch id 201 loss 0.5153539776802063 train acc 0.753731343283582\n",
      "epoch 6 batch id 401 loss 0.7021451592445374 train acc 0.7560785536159601\n",
      "epoch 6 batch id 601 loss 0.5945965647697449 train acc 0.7652870216306157\n",
      "epoch 6 train acc 0.7679679966248795\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4dd85f4beb4a79b65479827fa1eba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 test acc 0.577689910510437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5252566d3e124c2c9539a4efef802c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 0.5908110737800598 train acc 0.8125\n",
      "epoch 7 batch id 201 loss 0.3998739719390869 train acc 0.7939987562189055\n",
      "epoch 7 batch id 401 loss 0.6436739563941956 train acc 0.7960567331670823\n",
      "epoch 7 batch id 601 loss 0.45449110865592957 train acc 0.8043235232945092\n",
      "epoch 7 train acc 0.8069489951345665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c099a4044bae4ab59487c409073e1f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 test acc 0.5832001946754729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62579a1839e41cbb987d0ad46b5880c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 0.5446958541870117 train acc 0.7890625\n",
      "epoch 8 batch id 201 loss 0.2681998312473297 train acc 0.8267257462686567\n",
      "epoch 8 batch id 401 loss 0.47047412395477295 train acc 0.8288263715710723\n",
      "epoch 8 batch id 601 loss 0.39722174406051636 train acc 0.8349885607321131\n",
      "epoch 8 train acc 0.8364032228017884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5e521298184da08266c1ee0d4d5799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 test acc 0.5851647861627528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bee1136b85478290124310fe347ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 0.46010541915893555 train acc 0.8046875\n",
      "epoch 9 batch id 201 loss 0.25465598702430725 train acc 0.8528451492537313\n",
      "epoch 9 batch id 401 loss 0.5026413798332214 train acc 0.851932668329177\n",
      "epoch 9 batch id 601 loss 0.352687269449234 train acc 0.8553062603993344\n",
      "epoch 9 train acc 0.8561032973174366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc03387653ad404f872c89899d4d7ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 test acc 0.5866643478881278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80186711eb924682ac351331e9f92ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.40991273522377014 train acc 0.859375\n",
      "epoch 10 batch id 201 loss 0.2087116837501526 train acc 0.863339552238806\n",
      "epoch 10 batch id 401 loss 0.47499048709869385 train acc 0.8633299563591023\n",
      "epoch 10 batch id 601 loss 0.4044005274772644 train acc 0.8653156198003328\n",
      "epoch 10 train acc 0.8662211251862891\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9269191d1204c819c875792d6847508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/168 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 test acc 0.5862808575913242\n"
     ]
    }
   ],
   "source": [
    "best = 0.0\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "    if best <  (test_acc / (batch_id+1)):\n",
    "        MODEL_PATH = \"../myModel\"\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_PATH, \"oui_20240327.pt\"))\n",
    "        best = test_acc / (batch_id+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5035828-bb53-446c-b99e-d1898aab7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH = \"../myModel\"\n",
    "# torch.save(model.state_dict(), os.path.join(MODEL_PATH, \"oui_20240327.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c773ee52-1d72-4237-8946-911c65008878",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = nlp.data.TSVDataset(os.path.join(\"../dataset/test\", \"test.tsv\"), num_discard_samples=1)\n",
    "data_test = BERTDataset(test_dataset, 0, 1, tok, max_len, True, False)\n",
    "test_dataloader = DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ff5ac47a-d691-4b5f-8f01-3ea4cddef369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb22cfda46b4aec8f348d8383750e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.044270833333336 94\n",
      "test acc 0.5855773492907802\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_acc = 0.0\n",
    "for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "    token_ids = token_ids.long().to(device)\n",
    "    segment_ids = segment_ids.long().to(device)\n",
    "    valid_length= valid_length\n",
    "    label = label.long().to(device)\n",
    "    out = model(token_ids, valid_length, segment_ids)\n",
    "    test_acc += calc_accuracy(out, label)\n",
    "print(\"test acc {}\".format(test_acc/(batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eecdf14-36fa-442e-9d76-5fa8f944cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8debc124-b038-49be-82f2-e3054c226bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oui:\n",
    "    def __init__(self, bertmodel, vocab, device, train_dataloader, test_dataloader, fixed, hp, log_interval, num_epochs ,batch_size=128, max_len=100):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.log_interval = log_interval\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "    \n",
    "        # Hyper-parameter random sampling\n",
    "        params = dict()\n",
    "        if not fixed:\n",
    "            for name, value_info in hp.items():\n",
    "                #print(value_info, len(value_info))\n",
    "                if value_info[1] == 'max_grad_norm':\n",
    "                    params[name] = np.random.choice(value_info[0])\n",
    "                elif value_info[1] == 'int':\n",
    "                    params[name] = np.random.randint(min(value_info[0]), max(value_info[0])+1)\n",
    "                elif value_info[1] == 'float':\n",
    "                    params[name] = np.random.uniform(min(value_info[0]), max(value_info[0]))\n",
    "        else:\n",
    "            params['dr_rate']=0.5 #0.3 #0.2282168316541426 #0.3\n",
    "            params['learning_rate']=5e-5 #4.4397570365495904e-05 #5e-5\n",
    "            params['max_grad_norm']=1 #3 #1\n",
    "            params['warmup_ratio']=0.1 #0.2503085518907766 #0.1\n",
    "            params['weight_decay']=0.01 #0.009198865305723895 #0.01\n",
    "        \n",
    "        self.params = params\n",
    "        print(self.params)\n",
    "\n",
    "        self.model=BERTClassifier(bertmodel,  dr_rate=params[\"dr_rate\"]).to(device)\n",
    "        ## weight decay \n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': params[\"weight_decay\"]},\n",
    "            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        ## optimizer & loss\n",
    "        self.optimizer = AdamW(optimizer_grouped_parameters, lr=params[\"learning_rate\"])\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        ## learning rate scheduler\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        t_total = len(self.train_dataloader) * num_epochs\n",
    "        warmup_step = int(t_total * params[\"warmup_ratio\"])\n",
    "        self.scheduler = get_cosine_schedule_with_warmup(self.optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "\n",
    "        # predict\n",
    "        self.kkma = Kkma()\n",
    "        tokenizer = get_tokenizer()\n",
    "        self.tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "        self.emotion_to_idx = {0:'분노', 1:'당황', 2:'슬픔', 3:'기쁨', 4:'불안', 5:\"느긋\"}\n",
    "        self.idx_to_emotion = {\"분노\": 0, \"당황\":1, \"슬픔\":2, \"기쁨\":3, \"불안\":4, \"느긋\":5}    \n",
    "\n",
    "    # 예측\n",
    "    def predict(self, X, device):\n",
    "        X_split = self.kkma.sentences(X)\n",
    "        sentences = [[re.sub('[^a-zA-Z가-힣ㄱ-ㅎㅏ-ㅣ\\s]','',x).replace(\" \", \"\"), 0]  for x in X_split]\n",
    "        print(sentences)\n",
    "        data_test = BERTDataset(sentences, 0, 1, self.tok, self.max_len, True, False)\n",
    "        test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=self.batch_size, num_workers=5)\n",
    "\n",
    "        self.model.eval()\n",
    "        test_eval_list = []\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "    \n",
    "            valid_length= valid_length\n",
    "            label = label.long().to(device)\n",
    "    \n",
    "            out = self.model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "            test_eval=[]\n",
    "            for i in out:\n",
    "                logits=i\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                print(logits)\n",
    "                \n",
    "                test_eval.append(self.emotion_to_idx[np.argmax(logits)])\n",
    "                print(test_eval)\n",
    "            test_eval_list.append(test_eval)\n",
    "        return test_eval_list\n",
    "\n",
    "    # 모델 load\n",
    "    def load(self, path, device, bertmodel):\n",
    "        self.model = BERTClassifier(bertmodel,  dr_rate=0.2282168316541426).to(device)\n",
    "        model_state_dict = torch.load(path, map_location=device)\n",
    "        self.model.load_state_dict(model_state_dict)\n",
    "        \n",
    "\n",
    "    # 정확도 계산\n",
    "    def calc_accuracy(self, X,y):\n",
    "        max_vals, max_indices = torch.max(X, 1)\n",
    "        train_acc = (max_indices == y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "        return train_acc\n",
    "\n",
    "    # 학습\n",
    "    def train(self, device):\n",
    "        self.train_verbose_dict = {}\n",
    "        self.train_score_dict = {}\n",
    "        self.test_score_dict = {}\n",
    "        self.params_list = []\n",
    "\n",
    "        max_acc = 0\n",
    "        self.be = 0\n",
    "        self.bestmodel = self.model\n",
    "        print(self.params)\n",
    "        for e in range(self.num_epochs):\n",
    "            train_acc = 0.0\n",
    "            test_acc = 0.0\n",
    "\n",
    "            train_loss = []\n",
    "            train_scores = []\n",
    "            self.model.train()\n",
    "            for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(self.train_dataloader), total=len(self.train_dataloader)):\n",
    "                self.optimizer.zero_grad()\n",
    "                token_ids = token_ids.long().to(device)\n",
    "                segment_ids = segment_ids.long().to(device)\n",
    "                valid_length= valid_length\n",
    "                label = label.long().to(device)\n",
    "                \n",
    "                out = self.model(token_ids, valid_length, segment_ids)\n",
    "                loss = self.loss_fn(out, label)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params[\"max_grad_norm\"])\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()  # Update learning rate schedule\n",
    "                train_acc += self.calc_accuracy(out, label)\n",
    "                \n",
    "                if batch_id % self.log_interval == 0:\n",
    "                    print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "                    train_loss.append(loss.data.cpu().numpy())\n",
    "                    train_scores.append(train_acc / (batch_id+1))\n",
    "            \n",
    "            print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "            self.train_score_dict[e] = train_acc / (batch_id+1)\n",
    "            self.train_verbose_dict[e] = (train_loss, train_scores) \n",
    "            \n",
    "            self.model.eval()\n",
    "            for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(self.test_dataloader), total=len(self.test_dataloader)):\n",
    "                token_ids = token_ids.long().to(device)\n",
    "                segment_ids = segment_ids.long().to(device)\n",
    "                valid_length= valid_length\n",
    "                label = label.long().to(device)\n",
    "                \n",
    "                out = self.model(token_ids, valid_length, segment_ids)\n",
    "                test_acc += self.calc_accuracy(out, label)\n",
    "            \n",
    "            print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "            self.test_score_dict[e] = test_acc / (batch_id+1)\n",
    "            if max_acc < self.test_score_dict[e]:\n",
    "                max_acc = self.test_score_dict[e]\n",
    "                self.bestmodel = self.model\n",
    "                self.be = e\n",
    "                \n",
    "        return self.bestmodel, self.train_score_dict[self.be], self.test_score_dict[self.be]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18559caf-f8c4-4b5a-ab00-1ad69f621f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'hp': {\n",
    "        'dr_rate': ([1e-1, 5e-1], 'float'),\n",
    "        'learning_rate': ([1e-5, 1e-3], 'float'),\n",
    "        'max_grad_norm': ([1, 3, 5], 'max_grad_norm'),\n",
    "        'warmup_ratio': ([1e-2, 3e-1], 'float'),\n",
    "        'weight_decay': ([1e-4, 1e-2] , 'float'),\n",
    "    },\n",
    "    'log_interval': 200,\n",
    "    'num_epochs': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "585db122-5b39-4e46-8c5c-1425c64b08d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/home/j-j10a506/.jdk/jdk8u402-b06'\n",
    "os.environ['PATH'] = f\"{os.environ.get('PATH')}:{os.environ.get('JAVA_HOME')}/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a77bd520-2607-4c0b-abc0-d8fa493b7c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr_rate': 0.2282168316541426, 'learning_rate': 4.4397570365495904e-05, 'max_grad_norm': 3, 'warmup_ratio': 0.2503085518907766, 'weight_decay': 0.009198865305723895}\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "oui = Oui(bertmodel, vocab, device, train_dataloader, test_dataloader, True, **config)\n",
    "oui.load(\"../myModel/oui_20240327.pt\", device, bertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0855ee92-264a-4e4b-abb7-bf9c89c031a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['아시끄러워소리좀줄였으면좋겠다', 0], ['나귀안먹었다', 0]]\n",
      "[ 0.93896294  0.26407677 -0.01857913  0.82859117 -0.20105541 -1.5416832 ]\n",
      "['분노']\n",
      "[ 1.4599817   0.11218978  0.78544724  0.5301367  -0.41732517 -2.646504  ]\n",
      "['분노', '분노']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['분노', '분노']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"아 시끄러워. 소리 좀 줄였으면 좋겠다. 나 귀 안먹었다!!!!!!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d1584d2-d52a-4dca-8e02-65c45a9e6ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['오늘떡볶이를먹었는데맛있었다', 0]]\n",
      "[-1.6993369 -1.4869488 -1.2186148  2.990341  -1.2543203  3.6374328]\n",
      "['느긋']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['느긋']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오늘 떡볶이를 먹었는데 맛있었다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66313456-cb7b-4617-9366-85e9f40e2a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['그래도이정도면성공했다', 0]]\n",
      "[-0.00164447  0.12928875  1.0824149  -1.103029   -0.4248172   0.00994094]\n",
      "['슬픔']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['슬픔']]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"그래도 이정도면 성공했다...\") #  {0:'분노', 1:'당황', 2:'슬픔', 3:'기쁨', 4:'불안', 5:\"느긋\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73e81222-ce80-4e2b-abba-d67df28c4d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['오늘은푹쉬었다기분이좋다', 0]]\n",
      "[-1.7089108 -1.6795552 -1.1885542  4.944749  -1.527644   2.3833554]\n",
      "['기쁨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['기쁨']]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오늘은 푹 쉬었다 기분이 좋다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7aba3ac-abc9-4da0-8ed2-cf0f6155b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['오늘은푹쉬었다', 0], ['기분이좋다', 0]]\n",
      "[-1.4346611 -1.58216   -1.0334294  5.3622437 -1.4215934  1.2479757]\n",
      "['기쁨']\n",
      "[-1.2587606 -1.5102684 -1.4196774  5.9655056 -1.3495058  0.6854899]\n",
      "['기쁨', '기쁨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['기쁨', '기쁨']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오늘은 푹 쉬었다. 기분이 좋다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef8342cc-b8ef-4c0b-9b0f-23340c1bbb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['이번주만버티면끝나힘내자', 0]]\n",
      "[-0.70630693 -1.039113    1.2975603   1.0058483  -0.63473684  0.66562396]\n",
      "['슬픔']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['슬픔']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"이번주만 버티면 끝나 힘내자!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "33afce58-0cf5-4443-b4f5-472647041f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['넌최고야아아아아아아', 0]]\n",
      "[-1.3186584 -1.5941619 -1.4129112  5.661271  -1.559342   1.4824171]\n",
      "['기쁨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['기쁨']]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"넌 최고야아아아아아아\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ac93c26-3b84-44b2-99df-8d6e807ff4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['재택근무재즈작업카페매장독서힐링잠들기전사무실커피뉴에이지명상재즈낭만', 0]]\n",
      "[-1.0881397 -1.3204321 -1.3050059  5.7505355 -1.1264142  0.1805162]\n",
      "['기쁨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['기쁨']]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"재택근무. '재즈'. '작업'. '카페'. '매장'. '독서'. '힐링'. '잠들기전'. '사무실'. '커피'. '뉴에이지'. '명상'. '재즈'. '낭만'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aaa53842-f1f5-4618-9e2c-66d2910614a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['떠나는길에니가내게말했지너는바라는게너무나많아잠깐이라도널안바라보면머리에불이나버린다니까', 0], ['나는흐르려는눈물을참고하려던얘길어렵게누르고그래미안해라는한마디로너랑나눈날들마무리했었지달디달고달디달고달디단밤양갱밤양갱내가먹고싶었던건달디단밤양갱밤양갱이야떠나는길에니가내게말했지너는바라는게너무나많아아냐내가늘바란건하나야한개뿐이야달디단밤양갱달디달고달디달고달디단밤양갱밤양갱내가먹고싶었던건달디단밤양갱밤양갱이야', 0]]\n",
      "[ 2.7328718   0.56082225  1.140427   -3.4001148   1.1493524  -3.031311  ]\n",
      "['분노']\n",
      "[ 0.40829292  1.291262    2.586315   -2.1231759  -0.58100814 -1.5883467 ]\n",
      "['분노', '슬픔']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['분노', '슬픔']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"떠나는 길에 니가 내게 말했지 너는 바라는 게 너무나 많아 잠깐이라도 널 안 바라보면 머리에 불이 나버린다니까 나는 흐르려는 눈물을 참고 하려던 얘길 어렵게 누르고 그래 미안해라는 한 마디로 너랑 나눈 날들 마무리했었지 달디달고 달디달고 달디단 밤양갱 밤양갱 내가 먹고 싶었던 건 달디단 밤양갱 밤양갱이야 떠나는 길에 니가 내게 말했지 너는 바라는 게 너무나 많아 아냐 내가 늘 바란 건 하나야 한 개뿐이야 달디단 밤양갱 달디달고 달디달고 달디단 밤양갱 밤양갱 내가 먹고 싶었던 건 달디단 밤양갱 밤양갱이야\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0003f989-645f-4cff-a68c-75182280aade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['오빠나완성했어', 0], ['대박이지', 0]]\n",
      "[-0.85560447 -0.38656846  0.3335202   0.9191572  -0.990793    1.2560804 ]\n",
      "['느긋']\n",
      "[-1.3730785 -1.5239209 -1.1816858  5.1094117 -1.2090582  1.4085342]\n",
      "['느긋', '기쁨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['느긋', '기쁨']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오빠 나 완성했어!!!!!!! 대박이지?!?!?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d525b349-5371-440e-b04e-edf8989cccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['비온뒤무지개', 0]]\n",
      "[-0.86147183 -0.7022993  -0.50529355  3.856172   -0.38319296 -0.65039045]\n",
      "['기쁨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['기쁨']]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"비온 뒤 무지개!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb014be-5987-4ec9-ba32-3872c1b57d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb799d49-2e75-4179-9e10-495ff7772458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3be0a-1165-46bd-8328-738aa0413a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2377ae-5039-4a95-9c59-55dde4d18ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5878f405-3135-41d5-8e55-a0ecf6e09c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr_rate': 0.5, 'learning_rate': 5e-05, 'max_grad_norm': 1, 'warmup_ratio': 0.1, 'weight_decay': 0.01}\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "oui = Oui(bertmodel, vocab, device, train_dataloader, test_dataloader, True, **config)\n",
    "oui.load(\"../myModel/oui_20240327.pt\", \"cpu\", bertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "06de458a-afcc-4fa5-8cd7-3b022373d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['비온뒤무지개', 0]]\n",
      "[-0.99661195 -0.8946776  -0.35201007  5.1848445  -0.70639396 -0.67166615]\n",
      "['기쁨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['기쁨']]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"비온 뒤 무지개!\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b0253080-39a0-4eed-a363-b6d1d48fb731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['떠나는길에니가내게말했지너는바라는게너무나많아잠깐이라도널안바라보면머리에불이나버린다니까', 0], ['나는흐르려는눈물을참고하려던얘길어렵게누르고그래미안해라는한마디로너랑나눈날들마무리했었지달디달고달디달고달디단밤양갱밤양갱내가먹고싶었던건달디단밤양갱밤양갱이야떠나는길에니가내게말했지너는바라는게너무나많아아냐내가늘바란건하나야한개뿐이야달디단밤양갱달디달고달디달고달디단밤양갱밤양갱내가먹고싶었던건달디단밤양갱밤양갱이야', 0]]\n",
      "[ 2.5409856   0.15911539  1.4782271  -2.996636    1.7618265  -3.246282  ]\n",
      "['분노']\n",
      "[-0.19877008 -0.8851231   0.26179868  2.67469    -1.406069    0.51363176]\n",
      "['분노', '기쁨']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['분노', '기쁨']]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"떠나는 길에 니가 내게 말했지 너는 바라는 게 너무나 많아 잠깐이라도 널 안 바라보면 머리에 불이 나버린다니까 나는 흐르려는 눈물을 참고 하려던 얘길 어렵게 누르고 그래 미안해라는 한 마디로 너랑 나눈 날들 마무리했었지 달디달고 달디달고 달디단 밤양갱 밤양갱 내가 먹고 싶었던 건 달디단 밤양갱 밤양갱이야 떠나는 길에 니가 내게 말했지 너는 바라는 게 너무나 많아 아냐 내가 늘 바란 건 하나야 한 개뿐이야 달디단 밤양갱 달디달고 달디달고 달디단 밤양갱 밤양갱 내가 먹고 싶었던 건 달디단 밤양갱 밤양갱이야\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e61876-eaab-41c7-b3fb-d1471a0585eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oui3.8",
   "language": "python",
   "name": "oui3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
