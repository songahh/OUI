{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab0fa98-a2be-40f8-8163-0a67346a66f4",
   "metadata": {},
   "source": [
    "# OUI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e0d87-5897-4adc-9873-fd94ace9576b",
   "metadata": {},
   "source": [
    "### package load 및 device 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "51da7edb-72f9-4bcc-a370-a136d8d28884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "34a33eca-3547-4a04-8846-f1e920d6c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "37d53e82-ada4-4c6d-bc15-ef7da3927778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d8749721-bbda-4149-8a03-77597413c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/home/j-j10a506/.jdk/jdk8u402-b06'\n",
    "os.environ['PATH'] = f\"{os.environ.get('PATH')}:{os.environ.get('JAVA_HOME')}/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9f8d9bff-8978-4c1b-a257-d56653465083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda:3\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72321491-de20-412f-8ef0-4980c75b404b",
   "metadata": {},
   "source": [
    "### 데이터세트 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "279a664f-147e-4b7d-94c5-844ceba7795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = []\n",
    "        self.labels = []\n",
    "        for i in dataset:\n",
    "            if len(i)!=2:\n",
    "                continue\n",
    "\n",
    "            self.sentences.append(transform([i[sent_idx]]))\n",
    "            self.labels.append(np.int32(i[label_idx]))\n",
    "        \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "90753b05-515a-4b7c-aa02-b0cc893cb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=6,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "\n",
    "        print(token_ids.shape)\n",
    "        print(valid_length.shape)\n",
    "        print(segment_ids)\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "59ff73b1-7e88-4cfa-85e1-33ad0036fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oui:\n",
    "    def __init__(self, data_path, nc, batch_size=128, max_len=100):\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # pretrained model & tokenizer load\n",
    "        self.bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")\n",
    "        tokenizer = get_tokenizer()\n",
    "        self.tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "        self.model = None\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        # dataset 로드\n",
    "        self.__load_data__(data_path, batch_size, max_len, self.tok)\n",
    "\n",
    "        # predict\n",
    "        self.kkma = Kkma()\n",
    "        self.emotion_to_idx = {0:'분노', 1:'당황', 2:'슬픔', 3:'기쁨', 4:'불안', 5:\"느긋\"}\n",
    "        self.idx_to_emotion = {\"분노\": 0, \"당황\":1, \"슬픔\":2, \"기쁨\":3, \"불안\":4, \"느긋\":5}\n",
    "\n",
    "    '''데이터 로드'''\n",
    "    def __load_data__(self, data_path, batch_size, max_len, tok):\n",
    "        train_dataset = nlp.data.TSVDataset(os.path.join(data_path, \"train/train.tsv\"), num_discard_samples=1)\n",
    "        valid_dataset = nlp.data.TSVDataset(os.path.join(data_path, \"test/valid.tsv\"), num_discard_samples=1)\n",
    "        test_dataset = nlp.data.TSVDataset(os.path.join(data_path, \"test/test.tsv\"), num_discard_samples=1)\n",
    "\n",
    "        data_train = BERTDataset(train_dataset, 0, 1, tok, max_len, True, False)\n",
    "        data_valid = BERTDataset(valid_dataset, 0, 1, tok, max_len, True, False)\n",
    "        data_test = BERTDataset(test_dataset, 0, 1, tok, max_len, True, False)\n",
    "        \n",
    "        self.train_dataloader = DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "        self.valid_dataloader = DataLoader(data_valid, batch_size=batch_size, num_workers=5)\n",
    "        self.test_dataloader = DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
    "        \n",
    "\n",
    "    '''하이퍼파라미터 튜닝'''\n",
    "    def __tune_parameters__(self, parameters):\n",
    "        params = dict()\n",
    "        for name, value_info in parameters.items():\n",
    "            if value_info[1] == 'max_grad_norm':\n",
    "                params[name] = np.random.choice(value_info[0])\n",
    "            elif value_info[1] == 'int':\n",
    "                params[name] = np.random.randint(min(value_info[0]), max(value_info[0])+1)\n",
    "            elif value_info[1] == 'float':\n",
    "                params[name] = np.random.uniform(min(value_info[0]), max(value_info[0]))\n",
    "        return params\n",
    "\n",
    "    '''모델 로드'''\n",
    "    def __load_model__(self, dr_rate=0.5, lr=5e-5, wr=0.1, wd=0.01, device=\"cpu\", num_epochs=10):\n",
    "        if not self.model:\n",
    "            self.model = BERTClassifier(self.bertmodel, dr_rate=dr_rate).to(device)\n",
    "            no_decay = ['bias', 'LayerNorm.weight']\n",
    "            optimizer_grouped_parameters = [\n",
    "                {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': wd},\n",
    "                {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "            ]\n",
    "\n",
    "            ## optimizer & loss\n",
    "            self.optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "            self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "            t_total = len(self.train_dataloader) * num_epochs\n",
    "            warmup_step = int(t_total * wr)\n",
    "            self.scheduler = get_cosine_schedule_with_warmup(self.optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
    "        return self.model\n",
    "    \n",
    "    '''학습 함수'''\n",
    "    def train(self,export_path, parameters=None, log_interval=200, num_epochs=10, device=\"cpu\"):\n",
    "        params = dict()\n",
    "        if parameters:         # 하이퍼파라미터 튜닝\n",
    "            params = self.__tune_parameters__(parameters)\n",
    "        else:\n",
    "            params['dr_rate']=0.5\n",
    "            params['learning_rate']=5e-5 \n",
    "            params['max_grad_norm']=1\n",
    "            params['warmup_ratio']=0.1\n",
    "            params['weight_decay']=0.01\n",
    "\n",
    "        self.model = self.__load_model__(params['dr_rate'], params['learning_rate'], params['warmup_ratio'], params[\"weight_decay\"], device)\n",
    "\n",
    "        max_acc = 0.0\n",
    "        best_epoch = 0\n",
    "        for e in range(self.num_epochs):\n",
    "            train_acc = 0.0\n",
    "            test_acc = 0.0\n",
    "\n",
    "            # 학습\n",
    "            self.model.train()\n",
    "            for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(self.train_dataloader), total=len(self.train_dataloader)):\n",
    "                self.optimizer.zero_grad()\n",
    "                token_ids = token_ids.long().to(device)\n",
    "                segment_ids = segment_ids.long().to(device)\n",
    "                valid_length= valid_length\n",
    "                label = label.long().to(device)\n",
    "                \n",
    "                out = self.model(token_ids, valid_length, segment_ids)\n",
    "                loss = self.loss_fn(out, label)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params[\"max_grad_norm\"])\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()  # Update learning rate schedule\n",
    "                train_acc += self.__cal_acc__(out, label)\n",
    "                \n",
    "                if batch_id % self.log_interval == 0:\n",
    "                    print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "\n",
    "            train_acc =  train_acc/(batch_id+1)\n",
    "            print(\"epoch {} train acc {}\".format(e+1,train_acc))\n",
    "\n",
    "            # 평가\n",
    "            self.model.eval()\n",
    "            for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(self.valid_dataloader), total=len(self.valid_dataloader)):\n",
    "                token_ids = token_ids.long().to(device)\n",
    "                segment_ids = segment_ids.long().to(device)\n",
    "                valid_length= valid_length\n",
    "                label = label.long().to(device)\n",
    "                \n",
    "                out = self.model(token_ids, valid_length, segment_ids)\n",
    "                valid_acc += self.__cal_acc__(out, label)\n",
    "\n",
    "            valid_acc = valid_acc/(batch_id+1)\n",
    "            print(\"epoch {} test acc {}\".format(e+1, valid_acc))\n",
    "\n",
    "            # best acc 모델 저장\n",
    "            if max_acc < valid_acc: \n",
    "                max_acc = valid_acc\n",
    "                best_epoch = e\n",
    "                self.export_model(export_path, \"best_{}_epoch{}_acc{}.pt\".format(self.__today__formatted__(),best_epoch,max_acc*100//100))\n",
    "        \n",
    "\n",
    "    # '''예측 함수'''\n",
    "    def predict(self, X, device=\"cpu\"):\n",
    "        #X_split = self.kkma.sentences(X)\n",
    "        X_split = [X]\n",
    "        sentences = [[re.sub('[^a-zA-Z가-힣ㄱ-ㅎㅏ-ㅣ\\s]','',x).replace(\" \", \"\"), 0]  for x in X_split]\n",
    "        data_test = BERTDataset(sentences, 0, 1, self.tok, self.max_len, True, False)\n",
    "        test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=self.batch_size, num_workers=5)\n",
    "\n",
    "        self.model = self.__load_model__(device)\n",
    "        self.model.eval()\n",
    "        test_eval_list = []\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "            token_ids = token_ids.long().to(device)\n",
    "            segment_ids = segment_ids.long().to(device)\n",
    "    \n",
    "            valid_length= valid_length\n",
    "            label = label.long().to(device)\n",
    "    \n",
    "            out = self.model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "            test_eval=[]\n",
    "            for i in out:\n",
    "                logits=i\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                \n",
    "                positive_indices = np.where(logits > 0.5)[0]\n",
    "                positive_values = logits[positive_indices]\n",
    "                sorted_indices = positive_indices[np.argsort(positive_values)[::-1]]\n",
    "                emotions = list(map(lambda x: self.emotion_to_idx[x], sorted_indices))\n",
    "                test_eval.append((logits, emotions))\n",
    "                #test_eval.append((logits,self.emotion_to_idx[np.argmax(logits)]))\n",
    "            test_eval_list.append(test_eval)\n",
    "        return test_eval_list\n",
    "\n",
    "    '''정확도 계산'''\n",
    "    def __cal_acc__(self, X, y):\n",
    "        max_vals, max_indices = torch.max(X, 1)\n",
    "        train_acc = (max_indices == y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "        return train_acc\n",
    "\n",
    "    '''모델 저장'''\n",
    "    def export_model(self, export_path, export_name):\n",
    "        torch.save(model.state_dict(), os.path.join(export_path, export_name))\n",
    "        print(\"************************************모델 저장************************************************\")        \n",
    "\n",
    "    '''모델 로드'''\n",
    "    def import_model(self, path, device):\n",
    "        self.model = self.__load_model__(device=device)\n",
    "        model_state_dict = torch.load(path, map_location=device)\n",
    "        self.model.load_state_dict(model_state_dict)\n",
    "        print(\"************************************모델 로드************************************************\")        \n",
    "\n",
    "    ''' 날짜 포맷'''\n",
    "    def __today__formatted__(self):\n",
    "        today = datetime.datetime.today()\n",
    "        return str(today.year) + str(today.month) + str(today.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4eecdf14-36fa-442e-9d76-5fa8f944cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'parameters': {\n",
    "        'dr_rate': ([1e-1, 5e-1], 'float'),\n",
    "        'learning_rate': ([1e-5, 1e-3], 'float'),\n",
    "        'max_grad_norm': ([1, 3, 5], 'max_grad_norm'),\n",
    "        'warmup_ratio': ([1e-2, 3e-1], 'float'),\n",
    "        'weight_decay': ([1e-4, 1e-2] , 'float'),\n",
    "    },\n",
    "    'log_interval': 200,\n",
    "    'num_epochs': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "18559caf-f8c4-4b5a-ab00-1ad69f621f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_v1.zip\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "************************************모델 로드************************************************\n"
     ]
    }
   ],
   "source": [
    "oui = Oui(\"../dataset\", 6)\n",
    "oui.import_model(\"../myModel/oui_20240327_acc59.pt\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "2d1584d2-d52a-4dca-8e02-65c45a9e6ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(array([-1.6993368, -1.486949 , -1.218615 ,  2.9903407, -1.2543204,\n",
       "           3.6374338], dtype=float32),\n",
       "   ['느긋', '기쁨'])]]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오늘 떡볶이를 먹었는데 맛있었다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "66313456-cb7b-4617-9366-85e9f40e2a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(array([-0.00164383,  0.12928936,  1.0824162 , -1.1030301 , -0.42481732,\n",
       "           0.00993926], dtype=float32),\n",
       "   ['슬픔'])]]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"그래도 이정도면 성공했다...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d7aba3ac-abc9-4da0-8ed2-cf0f6155b2f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(array([-1.7089108, -1.6795555, -1.1885538,  4.9447465, -1.5276444,\n",
       "           2.3833578], dtype=float32),\n",
       "   ['기쁨', '느긋'])]]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오늘은 푹 쉬었다. 기분이 좋다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ef8342cc-b8ef-4c0b-9b0f-23340c1bbb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([-1.0346911 , -1.3176281 , -0.0993569 ,  4.19938   , -1.249438  ,\n",
       "           0.57501316], dtype=float32),\n",
       "   ['기쁨', '느긋'])]]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"다음주에 끝나!!! 힘내자!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "33afce58-0cf5-4443-b4f5-472647041f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([-1.3186585, -1.5941617, -1.4129113,  5.6612716, -1.559342 ,\n",
       "           1.4824166], dtype=float32),\n",
       "   ['기쁨', '느긋'])]]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"넌 최고야아아아아아아\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4ac93c26-3b84-44b2-99df-8d6e807ff4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([-1.0881395 , -1.3204317 , -1.3050059 ,  5.750535  , -1.1264136 ,\n",
       "           0.18051589], dtype=float32),\n",
       "   ['기쁨'])]]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"재택근무. '재즈'. '작업'. '카페'. '매장'. '독서'. '힐링'. '잠들기전'. '사무실'. '커피'. '뉴에이지'. '명상'. '재즈'. '낭만'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "aaa53842-f1f5-4618-9e2c-66d2910614a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([ 0.4595502 ,  1.7228955 ,  1.844803  , -2.0612774 , -0.45642117,\n",
       "          -1.3379616 ], dtype=float32),\n",
       "   ['슬픔', '당황'])]]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"떠나는 길에 니가 내게 말했지 너는 바라는 게 너무나 많아 잠깐이라도 널 안 바라보면 머리에 불이 나버린다니까 나는 흐르려는 눈물을 참고 하려던 얘길 어렵게 누르고 그래 미안해라는 한 마디로 너랑 나눈 날들 마무리했었지 달디달고 달디달고 달디단 밤양갱 밤양갱 내가 먹고 싶었던 건 달디단 밤양갱 밤양갱이야 떠나는 길에 니가 내게 말했지 너는 바라는 게 너무나 많아 아냐 내가 늘 바란 건 하나야 한 개뿐이야 달디단 밤양갱 달디달고 달디달고 달디단 밤양갱 밤양갱 내가 먹고 싶었던 건 달디단 밤양갱 밤양갱이야\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0003f989-645f-4cff-a68c-75182280aade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([-1.4889722, -1.4272162, -0.7195817,  3.7282648, -1.5424592,\n",
       "           2.2768848], dtype=float32),\n",
       "   ['기쁨', '느긋'])]]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오빠 나 완성했어!!!!!!! 대박이지?!?!?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d525b349-5371-440e-b04e-edf8989cccc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([-0.8614713 , -0.70230097, -0.50529486,  3.8561769 , -0.383195  ,\n",
       "          -0.6503905 ], dtype=float32),\n",
       "   ['기쁨'])]]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"비온 뒤 무지개!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9933cae6-e781-4a3f-ac33-5d336132a7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([ 3.4871686 ,  0.03877295,  1.159696  , -2.6744626 , -0.11092299,\n",
       "          -3.0513337 ], dtype=float32),\n",
       "   ['분노', '슬픔'])]]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"나 너무 화가 나 으악 이거 왜 이래\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cdc34095-7e2d-4627-9fbb-e272b9397fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([-0.24827906,  0.06239401,  0.46597284,  1.6907028 , -0.7146384 ,\n",
       "          -0.7499463 ], dtype=float32),\n",
       "   ['기쁨'])]]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"유경언니 잘가 고생해썽!!! 내일 봐아아아\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a89e0c5b-4c5a-4d11-b419-ca91f232f9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([ 2.2673976,  0.9862835,  2.077407 , -3.8068776,  0.3757995,\n",
       "          -2.9449425], dtype=float32),\n",
       "   ['분노', '슬픔', '당황'])]]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오늘 너무 피곤해 진짜 힘들었어... 나는 왜 이럴까\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8a774974-8912-49ea-a39f-066e121f0f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([ 0.69671607,  0.98253715,  2.342915  , -3.6035538 ,  1.462371  ,\n",
       "          -2.5276515 ], dtype=float32),\n",
       "   ['슬픔', '불안', '당황', '분노'])]]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"너무 어렵다 이문제...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "733ae118-a190-42a3-bb1b-b548c97c312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([ 2.1695783 ,  0.4398461 ,  0.93120855, -2.4109993 ,  1.3664936 ,\n",
       "          -3.0241697 ], dtype=float32),\n",
       "   ['분노', '불안', '슬픔'])]]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"에러가 너무 많이 터진다. 할일이 너무 많다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a455cb0d-dc84-48f1-92c1-e68e58d7c739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(array([-0.9345543 , -0.31555843,  1.2597854 ,  0.83889073, -1.3189985 ,\n",
       "           0.7683024 ], dtype=float32),\n",
       "   ['슬픔', '기쁨', '느긋'])]]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오늘 엄마랑 다이소에 갔다. 사고 싶은게 너무 많은데 못사서 슬펐다. 그래도 엄마랑 같이 다이소 구경해서 좋았다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156d1253-02bb-499e-b6db-ac2dd0e221ab",
   "metadata": {},
   "source": [
    "# OpenVino로 변환\n",
    "* pt -> onnx -> openvino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd57e00-d35d-4575-af8a-19ce015e75fa",
   "metadata": {},
   "source": [
    "### onnx 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bef71aa8-2986-461a-91ac-05d88d8e8ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(oui.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "89ed8e50-045f-4e89-ac5b-60016351a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "54643da7-4c85-4d83-a299-b3ee56e227ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = torch.randint(0, 20, (1, 100)).to(\"cpu\")\n",
    "valid_length = torch.randint(10, 21, (1,)).to(\"cpu\")\n",
    "segment_ids = torch.zeros(1, 100).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "020d88c1-4667-4b96-a40f-4ce47af18e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1285137/3279460756.py:18: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for i, v in enumerate(valid_length):\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(oui.model,               \n",
    "                  (token_ids,valid_length,segment_ids),                   \n",
    "                  \"../myModel/oui_240328.onnx\",   \n",
    "                  export_params=True,       \n",
    "                  input_names = ['input'],  \n",
    "                  output_names = ['output'], opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8dae4942-d04d-46d0-a38c-ed04c13af1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"../myModel/oui_240328.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2bf42fe1-6bad-41f7-8c15-5d6b72586a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_v1.zip\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/j-j10a506/oui/KoBERT/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")\n",
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "max_len=100\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "2b17f7bf-48aa-489b-ab27-58926be363ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "a6fe1854-b090-43ce-b15d-cd0923f382da",
   "metadata": {},
   "outputs": [],
   "source": [
    " def onnx_predict(X, device=\"cpu\"):\n",
    "    #X_split = self.kkma.sentences(X)\n",
    "    emotion_to_idx = {0:'분노', 1:'당황', 2:'슬픔', 3:'기쁨', 4:'불안', 5:\"느긋\"}\n",
    "    X_split = [X]\n",
    "    sentences = [[re.sub('[^a-zA-Z가-힣ㄱ-ㅎㅏ-ㅣ\\s]','',x).replace(\" \", \"\"), 0]  for x in X_split]\n",
    "    data_test = BERTDataset(sentences, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
    "    test_eval_list = []\n",
    "    model = onnxruntime.InferenceSession(\"../myModel/oui_240328.onnx\")\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.float().to(device)\n",
    "\n",
    "        valid_length= valid_length.long()\n",
    "        #print(valid_length.dtype)\n",
    "        #print(token_ids.dtype)\n",
    "        label = label.long().to(device)\n",
    "        inputs_info = model.get_inputs()\n",
    "        # for input_info in inputs_info:\n",
    "        #     print(\"Input Name:\", input_info.name)\n",
    "        #     print(\"Input Type:\", input_info.type)\n",
    "        #     print(\"Input Shape:\", input_info.shape)\n",
    "        #     print(\"--------------------------------------------------\")\n",
    "        out = model.run(None, {\"input\":np.array(token_ids), \"valid_length\": np.array(valid_length), \"inp\": np.array(segment_ids)})\n",
    "\n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i[0]\n",
    "            #print(logits)\n",
    "            positive_indices = np.where(logits > 0.5)[0]\n",
    "            positive_values = logits[positive_indices]\n",
    "            sorted_indices = positive_indices[np.argsort(positive_values)[::-1]]\n",
    "            emotions = list(map(lambda x: emotion_to_idx[x], sorted_indices))\n",
    "            test_eval.append((logits, emotions))\n",
    "            #test_eval.append((logits,self.emotion_to_idx[np.argmax(logits)]))\n",
    "        test_eval_list.append(test_eval)\n",
    "    return test_eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "885a85eb-3dff-450f-83c9-2497a4783798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([ 2.267396 ,  0.9862838,  2.0774078, -3.8068776,  0.3757988,\n",
       "          -2.9449413], dtype=float32),\n",
       "   ['분노', '슬픔', '당황'])]]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_predict(\"오늘 너무 피곤해 진짜 힘들었어... 나는 왜 이럴까\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "3a163e70-ef99-456d-a5e3-ec5a11ecc1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n",
      "torch.Size([1])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(array([ 2.2673976,  0.9862835,  2.077407 , -3.8068776,  0.3757995,\n",
       "          -2.9449425], dtype=float32),\n",
       "   ['분노', '슬픔', '당황'])]]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oui.predict(\"오늘 너무 피곤해 진짜 힘들었어... 나는 왜 이럴까\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ffff1-c2ff-430f-ab15-f564ef3e5bed",
   "metadata": {},
   "source": [
    "### openvino 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "d5201f3a-490f-466e-8254-5368b716d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.runtime import Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "8a4e1329-ed5d-4eaa-bda7-14a73c7bb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ie = Core()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "afa0e34a-d9fa-4bbe-a682-2b714085baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ie.read_model(model=\"../myModel/oui_240328.xml\", weights=\"../myModel/oui_240328.bin\")\n",
    "executable_network = ie.compile_model(model=network, device_name=\"CPU\")\n",
    "output_layer = next(iter(executable_network.outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "35117587-146a-4afc-964e-d68b84b17659",
   "metadata": {},
   "outputs": [],
   "source": [
    " def openvino_predict(X, device=\"cpu\"):\n",
    "    #X_split = self.kkma.sentences(X)\n",
    "    emotion_to_idx = {0:'분노', 1:'당황', 2:'슬픔', 3:'기쁨', 4:'불안', 5:\"느긋\"}\n",
    "    X_split = [X]\n",
    "    sentences = [[re.sub('[^a-zA-Z가-힣ㄱ-ㅎㅏ-ㅣ\\s]','',x).replace(\" \", \"\"), 0]  for x in X_split]\n",
    "    data_test = BERTDataset(sentences, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
    "    test_eval_list = []\n",
    "    model = onnxruntime.InferenceSession(\"../myModel/oui_240328.onnx\")\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.float().to(device)\n",
    "\n",
    "        valid_length= valid_length.long()\n",
    "        label = label.long().to(device)\n",
    "        inputs_info = model.get_inputs()\n",
    "        #out = model.run(None, {\"input\":np.array(token_ids), \"valid_length\": np.array(valid_length), \"inp\": np.array(segment_ids)})\n",
    "        out = executable_network([token_ids, valid_length, segment_ids])[output_layer]\n",
    "        \n",
    "        test_eval=[]\n",
    "        for i in out:\n",
    "            logits=i\n",
    "            #print(logits)\n",
    "            positive_indices = np.where(logits > 0.5)[0]\n",
    "            positive_values = logits[positive_indices]\n",
    "            sorted_indices = positive_indices[np.argsort(positive_values)[::-1]]\n",
    "            emotions = list(map(lambda x: emotion_to_idx[x], sorted_indices))\n",
    "            test_eval.append((logits, emotions))\n",
    "            #test_eval.append((logits,self.emotion_to_idx[np.argmax(logits)]))\n",
    "        test_eval_list.append(test_eval)\n",
    "    return test_eval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "2df30cc1-d0c5-485d-90c2-73d89ca98aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(array([ 2.265625  ,  0.98046875,  2.078125  , -3.8125    ,  0.37304688,\n",
       "          -2.953125  ], dtype=float32),\n",
       "   ['분노', '슬픔', '당황'])]]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openvino_predict(\"오늘 너무 피곤해 진짜 힘들었어... 나는 왜 이럴까\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e7306-a4d1-4667-8092-bde4025836da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oui3.8",
   "language": "python",
   "name": "oui3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
